{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parallel Tempering using pure Python (Multiprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallel tempering is a technique for improving the efficiency of MCMC, especially in the case of multi-modal target distributions. The core idea is to build a sequence of distributions starting with an easy-to-sample reference (e.g. the prior) and ending with the difficult-to-sample target (e.g. the posterior). Given the target $\\pi$ and the reference $\\pi_0$, this sequence is constructed using a \"temperature\" parameter $0 < \\beta < 1$:\n",
    "$$\\pi_\\beta = \\pi_0^{1-\\beta} \\cdot \\pi^\\beta$$\n",
    "Here, for $\\beta = 0$ (also referred to as \"cold\" chain) the distribution is equal to the target, for $\\beta = 1$ (also referred to as \"hot\" chain) it is equal to the reference. By running multiple chains with an ascending sequence of temperatures $\\beta_0 = 0, \\beta_1, \\dots, \\beta_n = 1$ and allowing theses chains to pass states based on Metropolis-Hastings, the simpler properties of hotter distributions improve the exploration of the state space and can result in faster convergence of the cold chain to the target distribution.\n",
    "\n",
    "*hopsy* implements parallel tempering. This notebook illustrates it by sampling a mixture of Gaussians that has two distinct modes. Depending on the starting point, vanilla MCMC approaches have trouble capturing the multi-modality. This is because once the chain has found a mode, Metropolis-Hastings proposal are very unlikely to propose high-density points in the other mode. With parallel tempering, the hotter chains are less effected by this and can better sample broadly. By passing these states on to the colder chains, other modes can be explored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-21T18:53:41.374022Z",
     "start_time": "2024-03-21T18:53:41.152579Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import hopsy\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sampling code with all imports must be defined within a file or function like here. The code is later called by an MPI process, enabling communication of the tempered chains in *HOPS*. Notice, that for the definition of the Markov chain, a synchronized `RandomNumberGenerator` (must have the same seed for each process!) and an exchange probability must be given.\n",
    "\n",
    "Important: Parallel tempering works best, if each chain runs on its own core. Therefore, it is not advised to use parallel tempering on machines with low core counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPI not supported on current platform",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m problem \u001b[38;5;241m=\u001b[39m hopsy\u001b[38;5;241m.\u001b[39mProblem(A, b, model)\n\u001b[1;32m     21\u001b[0m syncRng \u001b[38;5;241m=\u001b[39m hopsy\u001b[38;5;241m.\u001b[39mRandomNumberGenerator(seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4321\u001b[39m)\n\u001b[0;32m---> 23\u001b[0m mc \u001b[38;5;241m=\u001b[39m \u001b[43mhopsy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMarkovChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproposal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhopsy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGaussianCoordinateHitAndRunProposal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallelTemperingSyncRng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msyncRng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexchangeAttemptProbability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstarting_point\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m mc\u001b[38;5;241m.\u001b[39mproposal\u001b[38;5;241m.\u001b[39mstepsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.25\u001b[39m\n\u001b[1;32m     31\u001b[0m rng \u001b[38;5;241m=\u001b[39m hopsy\u001b[38;5;241m.\u001b[39mRandomNumberGenerator(rank \u001b[38;5;241m+\u001b[39m chain_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m11\u001b[39m)\n",
      "File \u001b[0;32m~/venv/lib/python3.11/site-packages/hopsy/misc.py:75\u001b[0m, in \u001b[0;36mMarkovChain\u001b[0;34m(problem, proposal, starting_point, parallelTemperingSyncRng, exchangeAttemptProbability)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     _proposal \u001b[38;5;241m=\u001b[39m proposal\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMarkovChain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_proposal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallelTemperingSyncRng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallelTemperingSyncRng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexchangeAttemptProbability\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexchangeAttemptProbability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPI not supported on current platform"
     ]
    }
   ],
   "source": [
    "class GaussianMixture:\n",
    "    def __init__(self, mu1, mu2):\n",
    "        epsilon = 0.05\n",
    "        cov = epsilon * np.eye(2, 2)\n",
    "        self.model1 = hopsy.Gaussian(mean=mu1, covariance=cov)\n",
    "        self.model2 = hopsy.Gaussian(mean=mu2, covariance=cov)\n",
    "\n",
    "    def log_density(self, x):\n",
    "        return np.log(\n",
    "            np.exp(-self.model1.compute_negative_log_likelihood(x))\n",
    "            + np.exp(-self.model2.compute_negative_log_likelihood(x))\n",
    "        )\n",
    "\n",
    "\n",
    "A = np.array([[1, 0], [0, 1], [-1, 0], [0, -1]])\n",
    "b = np.array([1, 1, 1, 1])\n",
    "\n",
    "model = GaussianMixture(np.ones(2).reshape(2, 1), -np.ones(2).reshape(2, 1))\n",
    "problem = hopsy.Problem(A, b, model)\n",
    "\n",
    "syncRng = hopsy.RandomNumberGenerator(seed=4321)\n",
    "\n",
    "mc = hopsy.MarkovChain(\n",
    "    proposal=hopsy.GaussianCoordinateHitAndRunProposal,\n",
    "    problem=problem,\n",
    "    parallelTemperingSyncRng=syncRng,\n",
    "    exchangeAttemptProbability=0.15,\n",
    "    starting_point=0.9 * np.ones(2),\n",
    "    parallel_tempering_backend\n",
    ")\n",
    "mc.proposal.stepsize = 0.25\n",
    "\n",
    "rng = hopsy.RandomNumberGenerator(rank + chain_idx + 11)\n",
    "\n",
    "acc_rate, samples = hopsy.sample(markov_chains=mc, rngs=rng, n_samples=n_samples)\n",
    "return acc_rate, samples, rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def run_tempered_chains(n_samples: int, n_temps: int, chain_idx: int):\n",
    "    with ipp.Cluster(engines='mpi', n=n_temps) as rc:\n",
    "        result = view.apply_sync(run_tempered_chain, n_samples, chain_idx)\n",
    "\n",
    "\n",
    "result = sorted(result, kdef\n",
    "run_tempered_chain(n_samples: int, chain_idx: int):\n",
    "import hopsy\n",
    "import numpy as np\n",
    "from mpi4py import MPI\n",
    "\n",
    "class GaussianMixture:\n",
    "    def __init__(self, mu1, mu2):\n",
    "        epsilon = 0.05\n",
    "        cov = epsilon * np.eye(2, 2)\n",
    "        self.model1 = hopsy.Gaussian(mean=mu1, covariance=cov)\n",
    "        self.model2 = hopsy.Gaussian(mean=mu2, covariance=cov)\n",
    "\n",
    "    def compute_negative_log_likelihood(self, x):\n",
    "        return -np.log(\n",
    "            np.exp(-self.model1.compute_negative_log_likelihood(x))\n",
    "            + np.exp(-self.model2.compute_negative_log_likelihood(x))\n",
    "        )\n",
    "\n",
    "\n",
    "A = np.array([[1, 0], [0, 1], [-1, 0], [0, -1]])\n",
    "b = np.array([1, 1, 1, 1])\n",
    "\n",
    "model = GaussianMixture(np.ones(2).reshape(2, 1), -np.ones(2).reshape(2, 1))\n",
    "problem = hopsy.Problem(A, b, model)\n",
    "\n",
    "replicates = 4\n",
    "n_chains = 5\n",
    "n_cores =  20\n",
    "\n",
    "\n",
    "assert n_chains>1\n",
    "temperature_ladder = [1. - index/(n_chains-1) for i in range(n_chains)]\n",
    "starting_point = .9 * np.ones(2)\n",
    "\n",
    "mcs = []\n",
    "rngs = []\n",
    "\n",
    "for replicate_id in range(replicates):\n",
    "    # this loops connects chains via shared memory\n",
    "    syncRng = hopsy.RandomNumberGenerator(replicate_id + 42)\n",
    "    shared_memory_names = hopsy.create_shared_memory(starting_point.shape)\n",
    "    mcs += [\n",
    "        hopsy.MarkovChain(\n",
    "            proposal=hopsy.GaussianCoordinateHitAndRunProposal,\n",
    "            problem=problem,\n",
    "            parallel_tempering_sync_rng=syncRng,\n",
    "            exchange_attempt_problem=0.15,\n",
    "            starting_point=starting_pint,\n",
    "            parallel_tempering_shared_memory=shared_memory_names,\n",
    "            parallel_tempering_coldness=c,\n",
    "        )\n",
    "        for c in temperature_ladder\n",
    "    ]\n",
    "    rngs += [\n",
    "        hopsy.RandomNumberGenerator(42+i,replicate_id)\n",
    "        for i in range(len(temperature_ladder))\n",
    "    ]\n",
    "\n",
    "for mc in mcs:\n",
    "    mc.proposal.stepsize = 0.25\n",
    "\n",
    "acc_rate, samples = hopsy.sample(markov_chains=mcs, rngs=rngs, n_samples=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "print(hopsy.rhat(samples), hopsy.ess(samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The cold chains seem to have converged. The following plot illustrates posteriors of all tempered distributions. The multi-modality is very well captured by all replicas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, n_replicas, sharey=True, figsize=(20, 5))\n",
    "for i in range(n_replicas):\n",
    "    ax = axs[i]\n",
    "ax.set_title(f\"replica {i + 1}\")\n",
    "for j in range(n_temps):\n",
    "    ax.hist(result[i][j][:, :, 0].flatten(), density=True, alpha=0.245, label=\"$\\\\beta_\" + str(j) + \"$\", bins=100)\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
