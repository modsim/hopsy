{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "308e7ea6-a739-406a-a37b-150c44a1c41e",
   "metadata": {},
   "source": [
    "# Sampling Genome-Scale Models\n",
    "\n",
    "In this notebook we demonstrate a few tricks to to sampling genome-scale models defined in SBML with maximum efficiency.\n",
    "To keep the compute times minimal in this demo, we demonstrate the required API calls using e_coli_core.\n",
    "\n",
    "Note, that we have used code similar to this to sample Recon3D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "187524d7-47b7-4ad4-90fb-23c5f0de01bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hopsy\n",
    "from PolyRound.api import PolyRoundApi\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c4c231-1f6d-4930-8360-231ed96fac49",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d578ad1e-8381-4de4-abdb-5b78df25906b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set parameter Username\n",
      "Academic license - for non-commercial use only - expires 2025-03-22\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(\"test_data\", \"e_coli_core.xml\")\n",
    "polytope = PolyRoundApi.sbml_to_polytope(model_path)\n",
    "# Note: gurobi is used here. Academic licenses are available for free. If you don't have gurobi, the fallback is glpk. glpk sometimes struggles with numerically challenging models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed808b8-c38f-4cd9-9e97-db99ee15e229",
   "metadata": {},
   "source": [
    "# Generate hopsy problem \n",
    "Generate the problem object from polytope definition & preprocess by bounding and rounding the polytope.\n",
    "We add the bounds to ensure the uniform distribution is well-defined on the polytope and we round to increase sampling efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe1723d-49c7-4002-bea2-3532493f1175",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rounding transformation took 9.300000169001578 seconds\n"
     ]
    }
   ],
   "source": [
    "problem = hopsy.Problem(polytope.A, polytope.b)\n",
    "problem = hopsy.add_box_constraints(problem, upper_bound=10_000, lower_bound=-10_000, simplify=True)\n",
    "start = time.perf_counter()\n",
    "problem = hopsy.round(problem)\n",
    "print(\"Computing rounding transformation took\", time.perf_counter()-start,\"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71a45c07-7547-4521-a8aa-cb032e48a60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(190, 95)\n",
      "(190,)\n",
      "(190, 95)\n",
      "(190,)\n"
     ]
    }
   ],
   "source": [
    "print(polytope.A.shape)\n",
    "print(polytope.b.shape)\n",
    "print(problem.A.shape)\n",
    "print(problem.b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b54a49-ba4f-4df3-9e75-4e7123b827ed",
   "metadata": {},
   "source": [
    "# Setup markov chains and random number generators\n",
    "We require to manually specify a seed, because it improves awareness of the seed. Specifically, the seed is required for scientific reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ca58ca-4c22-4247-af78-38b1251c439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 511\n",
    "chains, rngs = hopsy.setup(problem, seed, n_chains=4)\n",
    "n_samples = 10_000\n",
    "# Either use thinning rule, see  10.1371/journal.pcbi.1011378\n",
    "# or use one-shot transformation (for expert users). We show one-shot transformation at the end.\n",
    "thinning = int(1./6*problem.transformation.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a309568-dd87-455e-97d2-ab712d9d24a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling with internal trafo took 0.6584702769978321 seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "accrate, samples = hopsy.sample(chains, rngs, n_samples, thinning=thinning, n_procs=4)\n",
    "print(\"sampling with internal trafo took\", time.perf_counter()-start,\"seconds\")\n",
    "# accrate is 1 for uniform samples with the default chains given by hopsy.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3ed2a4-37d3-4237-97b3-2379b2218ccd",
   "metadata": {},
   "source": [
    "# Evaluate sampe quality\n",
    "For highest statistical quality, it is advised to check rhat < 1.01 and ess / n_chains > 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e34c39c-2698-41b5-8b4c-37d10d14041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rhat: 1.0019304367129511\n",
      "ess: 1426.2729062496408\n"
     ]
    }
   ],
   "source": [
    "rhat = np.max(hopsy.rhat(samples))\n",
    "print(\"rhat:\", rhat)\n",
    "ess = np.min(hopsy.ess(samples)) / len(chains)\n",
    "print(\"ess:\", ess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2932dec5-2f4c-424c-9c5c-5a670fc4528e",
   "metadata": {},
   "source": [
    "# Expert mode for speed: one shot backtransform\n",
    "By postponing the back transformation from rounded space to original space, we can obtain better performance for high-dimensional models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55369bc9-f5d1-4423-9d1a-1e4a0a95462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert problem.transformation is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5632f5fa-c4b1-4442-b9b7-868d15c2b312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampling took 1.0086242019970086 seconds\n",
      "sample shape (4, 10000, 95)\n",
      "rhat: 1.000227929785174\n",
      "ess: 9658.117836358155\n",
      "transformation took 0.019212077000702266 seconds\n",
      "sample stats are the same (save numerics) before and after the linear transformation:\n",
      "rhat: 1.0002279346424705\n",
      "ess: 9658.117836358155\n"
     ]
    }
   ],
   "source": [
    "# deep copy enures that we do not edit the original problem\n",
    "problem2 = copy.deepcopy(problem)\n",
    "problem2.transformation=None\n",
    "problem2.shift=None\n",
    "seed = 512\n",
    "chains, rngs = hopsy.setup(problem2, seed, n_chains=4)\n",
    "n_samples = 10_000\n",
    "# thinning is still advised when hard drive memory is limisted to not to store too many samples \n",
    "thinning = int(1*problem.A.shape[1])  \n",
    "start = time.perf_counter()\n",
    "accrate, sample_stack = hopsy.sample(chains, rngs, n_samples, thinning=thinning)\n",
    "print(\"sampling took\", time.perf_counter()-start,\"seconds\")\n",
    "# accrate is 1 for uniform samples with the default chains given by hopsy.setup()\n",
    "\n",
    "print('sample shape', sample_stack.shape)\n",
    "rhat = np.max(hopsy.rhat(sample_stack))\n",
    "print(\"rhat:\", rhat)\n",
    "ess = np.min(hopsy.ess(sample_stack)) / len(chains)\n",
    "print(\"ess:\", ess)\n",
    "\n",
    "# transform samples back all at once\n",
    "shift_t = np.array([problem.shift]).T\n",
    "start_trafo = time.perf_counter()\n",
    "full_samples = np.zeros((len(chains), n_samples, sample_stack.shape[2]))\n",
    "for i in range(len(chains)):\n",
    "    full_samples[i] = (problem.transformation@sample_stack[i].T).T + np.tile(shift_t, (1, n_samples)).T\n",
    "    \n",
    "print(\"transformation took\", time.perf_counter()-start_trafo,\"seconds\")\n",
    "print('sample stats are the same (save numerics) before and after the linear transformation:')\n",
    "rhat = np.max(hopsy.rhat(full_samples))\n",
    "print(\"rhat:\", rhat)\n",
    "ess = np.min(hopsy.ess(full_samples)) / len(chains)\n",
    "print(\"ess:\", ess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a82e02-7387-41b1-9d8f-daa3d7b729d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
